{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acef444b",
   "metadata": {},
   "source": [
    "# Webscraping Indeed for Job Titles with \"Sustainability\n",
    "## A Coding Temple Final Project\n",
    "### Pray a little prayer for this to work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de0dec2",
   "metadata": {},
   "source": [
    "### Step 1: I created a conda virtual environment (finalproject_env) specific to this project and created a jupyter notebook that is connected to it.\n",
    "For reference: https://www.youtube.com/watch?v=Ro9l0eapoJU\n",
    "### Step 2: Start scraping.\n",
    "I am using this as a reference: https://www.youtube.com/watch?v=g0QUvO8FfAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25430296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lxml\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import datetime\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c6b73c",
   "metadata": {},
   "source": [
    "### Wait step back. Step 1.9: Study the URL and the DOM\n",
    "\n",
    "- URL of interest: https://www.indeed.com/jobs?q=sustainability&l=California\n",
    "- When you click on a specific job: https://www.indeed.com/jobs?q=sustainability&l=California&vjk=7bb3f8f043419fbd\n",
    "    - there is a 'VJK' -- i think that means view job key?\n",
    "- When you click the next page: https://www.indeed.com/jobs?q=sustainability&l=California&start=10\n",
    "    - Increases by increments of 10\n",
    "- When you view a specific job: https://www.indeed.com/viewjob?jk=178c02cc700910ee\n",
    "\n",
    "All the job results are under \n",
    " - div class=\"mosaic-zone\" id='mosaic-zone-jobcards\"\n",
    "Followed by \n",
    " - div id=\"mosaic-provider-jobcards\" class=\"mosaic mosaic-provider-jobcards mosaic-provider-hydrated\"\n",
    "Each job card is an a tag that looks like this:\n",
    " - a id=\"sj_11cbe6c9847066e5\" data-mobtk=\"1f5n5mhkkoci8801\" data-jk=\"11cbe6c9847066e5\" rel=\"nofollow\" data-hide-spinner=\"true\" class=\"tapItem result job_11cbe6c9847066e5 sponsoredJob resultWithShelf sponTapItem tapItem-noPadding desktop\" href=\"/pagead/clk?mo=r&amp;ad=-6NYlbfkN0ADzOeDESdYpV-bYAZsPPyr0JcDhLaY3k_3Q-ZKMNEAQZWeExh7cVECWgbhx4LTlu3PsybHKn7Y2qLo9GTuybO9xyWSDLKErIwmyQJmWkWQZUWD_h0NfMIINqc8T4-VB9UaOHG5q3tgMSVSUaWUQ-FQKMo6AT0zyAjZytcnIJQz6Up2pN5eKi_IeMl8kHDFaDYUakmWZAdALULBof_4qpq2XF3BtEn_DaUrO3DVardnEFRnTjU1QjnbIw1yGloyYxanujuXi0tiYYJI7gE38sii2Rw1AsI4b7BvixiaCas31nnJf2aFoO_0PHafxlk9ZKvQnY7l1BbU4m6dbH7XO-egXVY7BmZKTuQUOsfClbbgJlWJT8pLfnCdg7uTR4d2ipB-oXMGvcMKdA0yezDxoot-ozJHI987qXZBFnn8d4yzQ8W0j7g1lvAwQsYTYg5BaygKLJMkfrSGh6C3IKflxGleV9UUWdnNwsc=&amp;p=0&amp;fvj=1&amp;vjs=3\" target=\"_blank\"\n",
    "    - div class=\"slider_container\"\n",
    "        - div class= \"slider_list\"\n",
    "            - div class = \"slider_item\"\n",
    "                - div class = \"job_seen_beacon\"\n",
    "                    - table class = \"jobCard_mainContent\" - this is the top DEETS\n",
    "                        - tbody --> tr --> tdclass = \"resultContent\n",
    "                            - <strong>JOB TITLE HERE</strong> div class=\"heading4 ...\" --> h2 class=jobTitle -> get the title attribute in span\n",
    "                            - <strong>COMPANY NAME HERE</strong> div class=\"heading6 ...\" --> pre --> span class=\"companyName\"\n",
    "                            - <strong>LOCATION HERE</strong> ... --> div class=\"companyLocation\"\n",
    "                    - table class = jobCardShelfContainer\"  - this is the bottom DEETS\n",
    "                        - tbody --> tr class = \"underShelfFooter\" --> td --> divclass=\"heading6 tapItem-gutter result-footer\"\n",
    "                            - <strong>JOB SNIPPET HERE</strong> divclass = \"job-snippet\" --> ul --> li\n",
    "\n",
    "Resource I used for modifying beautiful soup find_all/find paths, since the paths seems to have changed since the video was published: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc5516e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scrape for page 0/99.\n",
      "status code is  200\n",
      "Starting scrape for page 1/99.\n",
      "status code is  200\n",
      "Starting scrape for page 2/99.\n",
      "status code is  200\n",
      "Starting scrape for page 3/99.\n",
      "status code is  200\n",
      "Starting scrape for page 4/99.\n",
      "status code is  200\n",
      "Starting scrape for page 5/99.\n",
      "status code is  200\n",
      "Starting scrape for page 6/99.\n",
      "status code is  200\n",
      "Starting scrape for page 7/99.\n",
      "status code is  200\n",
      "Starting scrape for page 8/99.\n",
      "status code is  200\n",
      "Starting scrape for page 9/99.\n",
      "status code is  200\n",
      "Starting scrape for page 10/99.\n",
      "status code is  200\n",
      "Starting scrape for page 11/99.\n",
      "status code is  200\n",
      "Starting scrape for page 12/99.\n",
      "status code is  200\n",
      "Starting scrape for page 13/99.\n",
      "status code is  200\n",
      "Starting scrape for page 14/99.\n",
      "status code is  200\n",
      "Starting scrape for page 15/99.\n",
      "status code is  200\n",
      "Starting scrape for page 16/99.\n",
      "status code is  200\n",
      "Starting scrape for page 17/99.\n",
      "status code is  200\n",
      "Starting scrape for page 18/99.\n",
      "status code is  200\n",
      "Starting scrape for page 19/99.\n",
      "status code is  200\n",
      "Starting scrape for page 20/99.\n",
      "status code is  200\n",
      "Starting scrape for page 21/99.\n",
      "status code is  200\n",
      "Starting scrape for page 22/99.\n",
      "status code is  200\n",
      "Starting scrape for page 23/99.\n",
      "status code is  200\n",
      "Starting scrape for page 24/99.\n",
      "status code is  200\n",
      "Starting scrape for page 25/99.\n",
      "status code is  200\n",
      "Starting scrape for page 26/99.\n",
      "status code is  200\n",
      "Starting scrape for page 27/99.\n",
      "status code is  200\n",
      "Starting scrape for page 28/99.\n",
      "status code is  200\n",
      "Starting scrape for page 29/99.\n",
      "status code is  200\n",
      "Starting scrape for page 30/99.\n",
      "status code is  200\n",
      "Starting scrape for page 31/99.\n",
      "status code is  200\n",
      "Starting scrape for page 32/99.\n",
      "status code is  200\n",
      "Starting scrape for page 33/99.\n",
      "status code is  200\n",
      "Starting scrape for page 34/99.\n",
      "status code is  200\n",
      "Starting scrape for page 35/99.\n",
      "status code is  200\n",
      "Starting scrape for page 36/99.\n",
      "status code is  200\n",
      "Starting scrape for page 37/99.\n",
      "status code is  200\n",
      "Starting scrape for page 38/99.\n",
      "status code is  200\n",
      "Starting scrape for page 39/99.\n",
      "status code is  200\n",
      "Starting scrape for page 40/99.\n",
      "status code is  200\n",
      "Starting scrape for page 41/99.\n",
      "status code is  200\n",
      "Starting scrape for page 42/99.\n",
      "status code is  200\n",
      "Starting scrape for page 43/99.\n",
      "status code is  200\n",
      "Starting scrape for page 44/99.\n",
      "status code is  200\n",
      "Starting scrape for page 45/99.\n",
      "status code is  200\n",
      "Starting scrape for page 46/99.\n",
      "status code is  200\n",
      "Starting scrape for page 47/99.\n",
      "status code is  200\n",
      "Starting scrape for page 48/99.\n",
      "status code is  200\n",
      "Starting scrape for page 49/99.\n",
      "status code is  200\n",
      "Starting scrape for page 50/99.\n",
      "status code is  200\n",
      "Starting scrape for page 51/99.\n",
      "status code is  200\n",
      "Starting scrape for page 52/99.\n",
      "status code is  200\n",
      "Starting scrape for page 53/99.\n",
      "status code is  200\n",
      "Starting scrape for page 54/99.\n",
      "status code is  200\n",
      "Starting scrape for page 55/99.\n",
      "status code is  200\n",
      "Starting scrape for page 56/99.\n",
      "status code is  200\n",
      "Starting scrape for page 57/99.\n",
      "status code is  200\n",
      "Starting scrape for page 58/99.\n",
      "status code is  200\n",
      "Starting scrape for page 59/99.\n",
      "status code is  200\n",
      "Starting scrape for page 60/99.\n",
      "status code is  200\n",
      "Starting scrape for page 61/99.\n",
      "status code is  200\n",
      "Starting scrape for page 62/99.\n",
      "status code is  200\n",
      "Starting scrape for page 63/99.\n",
      "status code is  200\n",
      "Starting scrape for page 64/99.\n",
      "status code is  200\n",
      "Starting scrape for page 65/99.\n",
      "status code is  200\n",
      "Starting scrape for page 66/99.\n",
      "status code is  200\n",
      "Starting scrape for page 67/99.\n",
      "status code is  200\n",
      "Starting scrape for page 68/99.\n",
      "status code is  200\n",
      "Starting scrape for page 69/99.\n",
      "status code is  200\n",
      "Starting scrape for page 70/99.\n",
      "status code is  200\n",
      "Starting scrape for page 71/99.\n",
      "status code is  200\n",
      "Starting scrape for page 72/99.\n",
      "status code is  200\n",
      "Starting scrape for page 73/99.\n",
      "status code is  200\n",
      "Starting scrape for page 74/99.\n",
      "status code is  200\n",
      "Starting scrape for page 75/99.\n",
      "status code is  200\n",
      "Starting scrape for page 76/99.\n",
      "status code is  200\n",
      "Starting scrape for page 77/99.\n",
      "status code is  200\n",
      "Starting scrape for page 78/99.\n",
      "status code is  200\n",
      "Starting scrape for page 79/99.\n",
      "status code is  200\n",
      "Starting scrape for page 80/99.\n",
      "status code is  200\n",
      "Starting scrape for page 81/99.\n",
      "status code is  200\n",
      "Starting scrape for page 82/99.\n",
      "status code is  200\n",
      "Starting scrape for page 83/99.\n",
      "status code is  200\n",
      "Starting scrape for page 84/99.\n",
      "status code is  200\n",
      "Starting scrape for page 85/99.\n",
      "status code is  200\n",
      "Starting scrape for page 86/99.\n",
      "status code is  200\n",
      "Starting scrape for page 87/99.\n",
      "status code is  200\n",
      "Starting scrape for page 88/99.\n",
      "status code is  200\n",
      "Starting scrape for page 89/99.\n",
      "status code is  200\n",
      "Starting scrape for page 90/99.\n",
      "status code is  200\n",
      "Starting scrape for page 91/99.\n",
      "status code is  200\n",
      "Starting scrape for page 92/99.\n",
      "status code is  200\n",
      "Starting scrape for page 93/99.\n",
      "status code is  200\n",
      "Starting scrape for page 94/99.\n",
      "status code is  200\n",
      "Starting scrape for page 95/99.\n",
      "status code is  200\n",
      "Starting scrape for page 96/99.\n",
      "status code is  200\n",
      "Starting scrape for page 97/99.\n",
      "status code is  200\n",
      "Starting scrape for page 98/99.\n",
      "status code is  200\n",
      "Starting scrape for page 99/99.\n",
      "status code is  200\n",
      "Appended 1045 entries to jj list\n"
     ]
    }
   ],
   "source": [
    "#list of jobs\n",
    "jj = []\n",
    "counter = 0\n",
    "\n",
    "num_jobs = 1000\n",
    "\n",
    "for j in range(0, num_jobs, 10):\n",
    "    \n",
    "    print(f'Starting scrape for page {j//10 +1}/{num_jobs//10}.')\n",
    "    \n",
    "    #looping through the number of results page you want to parse, increments of 10\n",
    "    position, location = 'sustainability', 'United+States'\n",
    "    \n",
    "    if j < num_jobs//4 or j > num_jobs*3//4:\n",
    "        header = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36\"}\n",
    "    else:\n",
    "        header = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36\"}\n",
    "    \n",
    "    y = requests.get(f'https://www.indeed.com/jobs?q={position}&l={location}&start={str(j)}', headers = header)\n",
    "    \n",
    "    print('status code is ', str(y.status_code))\n",
    "    \n",
    "    time.sleep(3)\n",
    "    \n",
    "    sp = bs(y.text, 'lxml')\n",
    "    soup = sp.find('table',{\"id\":\"pageContent\"})\n",
    "    #print(soup.find_all(name='div',attrs={\"class\":\"jobsearch-SerpJobCard\"}))\n",
    "    #soup is the table with the results.\n",
    "    #confirmed 12:07 am 5/15 that it returns a list with different div jobsearch-serpjobcard.\n",
    "    #needed to run twice to get a title printed out. i think that's the carousel...\n",
    "#     print(sp)\n",
    "    for ii in soup.find_all(name='div',attrs={\"class\":\"jobsearch-SerpJobCard\"}):\n",
    "        #for each div tag with the class = \"jobsearch-SerpJobCard\"\n",
    "        job_title= ii.find('a',{\"class\":\"jobtitle\"})['title']\n",
    "        company_name= ii.find('span',{\"class\":\"company\"}).text.strip()\n",
    "        location= ii.find('span',{\"class\":\"location\"})\n",
    "         \n",
    "        if location:\n",
    "            location=location.text.strip()\n",
    "        else:\n",
    "            location=ii.find('div',{\"class\":\"location\"})\n",
    "            location=location.text.strip()\n",
    "                \n",
    "        #extracting the job key, which will lead us to the specific job's page\n",
    "        k=bs(str(ii), 'lxml')\n",
    "        jk=k.find(name='div', attrs={\"class\":\"jobsearch-SerpJobCard\"})\n",
    "        jobkey=jk['data-jk']\n",
    "    \n",
    "        job_dict={'job_title': job_title,\n",
    "                    'company_name': company_name,\n",
    "                    'location': location,\n",
    "                    'job_key': jobkey}\n",
    "        \n",
    "        counter += 1\n",
    "        jj.append(job_dict)\n",
    "\n",
    "print(f'Appended {counter} entries to jj list')\n",
    "\n",
    "## 2:59 a.m., 05/15/21. Stopped working at line 14. Returns \"Captcha Solve Page\"\n",
    "## 5:38 p.m, 05/15/21. Worked an hour ago. Scrapped 774 job listings fine, \n",
    "## but when extracting job descriptions from individual job pages, I noticed that it would return NaN for ~100? ish.\n",
    "## I think it might be from the captcha. \n",
    "### My options -- do in batches of ~100? do that 10 times.\n",
    "### -- Utilize user agents.\n",
    "### -- i just need to scrape the job #s first. then run the scraper for job descriptions in batches, \n",
    "### which is probably where the user agents will come more in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c505fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'job_title': 'Sustainability Intern',\n",
       "  'company_name': 'Imperfect Foods',\n",
       "  'location': 'Remote',\n",
       "  'job_key': 'f5438de8a8e1629a'},\n",
       " {'job_title': 'Environmental Sustainability Internship',\n",
       "  'company_name': 'Jellyfish',\n",
       "  'location': 'Providence, RI',\n",
       "  'job_key': '7075a3a7b5571059'},\n",
       " {'job_title': 'SUSTAINABILITY ANALYST',\n",
       "  'company_name': 'LONGEVITY PARTNERS',\n",
       "  'location': 'Austin, TX',\n",
       "  'job_key': '2171570f88a3a65d'},\n",
       " {'job_title': 'Sustainability Innovation Consultant',\n",
       "  'company_name': 'Amazon Web Services, Inc.',\n",
       "  'location': 'Remote',\n",
       "  'job_key': 'e862369e52ce2651'},\n",
       " {'job_title': 'Sustainability Associate',\n",
       "  'company_name': 'Schneider Electric',\n",
       "  'location': 'Louisville, KY',\n",
       "  'job_key': '00a0e465fe8342c8'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(jj))\n",
    "jj[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b7a5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert jj into a basic_jobs data frame. then convert to csv.\n",
    "basic_jobs = pd.DataFrame(jj)\n",
    "basic_jobs.to_csv('jobkeys.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f074ac",
   "metadata": {},
   "source": [
    "## Extract Data SUCCESS\n",
    "\n",
    "### ITS WORKING!!! It seems like indeed does have some kind of carousel on their website, based on how I need to run the kernel a few times to get it to actually scrape the data and go through the for loop on line 18. \n",
    "\n",
    "### Now we have jj, which is the list with distinct job dictionaries\n",
    "\n",
    "For reference, found another web scraping medium article: https://medium.com/@msalmon00/web-scraping-job-postings-from-indeed-96bd588dcb4b\n",
    "\n",
    "## Extract Data Part 2 - Job Descriptions\n",
    "\n",
    "### Now we will use job_key to open a new job page and scrape that page for job_descriptions. \n",
    "### To use different user_agents, I used this resource:\n",
    "https://www.youtube.com/watch?v=90t9WkQbQ2E&t=1s\n",
    "https://developers.whatismybrowser.com/useragents/explore/software_name/chrome/2\n",
    "\n",
    "## 5/15/21. User Agents not working? The job_keys were successfully extracted, but when I pull up each job page, I get a captcha. So , im gonna take a break and come back.\n",
    "\n",
    "Also, Monster.com scraping seems more complex than indeed.com, because Monster.com uses React - Hash Routing. It's not its own separate page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2f5d133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "jj = pd.read_csv('jobkeys.csv')\n",
    "jj.to_dict('list')\n",
    "jk= (jj['job_key'])\n",
    "print(type(jj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "683f6632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request for 641/1045 jobs\n",
      "https://www.indeed.com/viewjob?jk=7ccdf0e26697d45d\n",
      "\n",
      "Request for 642/1045 jobs\n",
      "https://www.indeed.com/viewjob?jk=276a9389cb202861\n",
      "\n",
      "Request for 643/1045 jobs\n",
      "https://www.indeed.com/viewjob?jk=4268026343e3a4c1\n",
      "\n",
      "Request for 644/1045 jobs\n",
      "https://www.indeed.com/viewjob?jk=881b5bcbe9326589\n",
      "\n",
      "Request for 645/1045 jobs\n",
      "https://www.indeed.com/viewjob?jk=cc46fe639cfce9d2\n",
      "\n",
      "Request for 646/1045 jobs\n",
      "https://www.indeed.com/viewjob?jk=800d7cc3e9f91c0e\n",
      "\n",
      "Request for 647/1045 jobs\n",
      "https://www.indeed.com/viewjob?jk=81b9a3fdaedeaa13\n",
      "\n",
      "Request for 648/1045 jobs\n",
      "https://www.indeed.com/viewjob?jk=d7b394daa4a026e4\n",
      "\n",
      "Request for 649/1045 jobs\n",
      "https://www.indeed.com/viewjob?jk=99ec1a8e0fe9d7d8\n",
      "\n",
      "Request for 650/1045 jobs\n",
      "https://www.indeed.com/viewjob?jk=c43018565495fbf0\n",
      "\n",
      "Request for 651/1045 jobs\n",
      "https://www.indeed.com/viewjob?jk=463400a6db4dbe34\n",
      "\n",
      "Request for 652/1045 jobs\n",
      "https://www.indeed.com/viewjob?jk=5a293f636f07bc21\n",
      "\n",
      "Request for 653/1045 jobs\n",
      "https://www.indeed.com/viewjob?jk=3025c35614045191\n",
      "\n",
      "Request for 654/1045 jobs\n",
      "https://www.indeed.com/viewjob?jk=27f438fa33dd2aac\n",
      "\n",
      "Request for 655/1045 jobs\n",
      "https://www.indeed.com/viewjob?jk=d54900ad7c984d32\n",
      "\n",
      "Request for 656/1045 jobs\n",
      "https://www.indeed.com/viewjob?jk=36f483c0992cea82\n",
      "\n",
      "Request for 657/1045 jobs\n",
      "https://www.indeed.com/viewjob?jk=d9d83fadfd311f53\n",
      "\n",
      "Request for 658/1045 jobs\n",
      "https://www.indeed.com/viewjob?jk=bfc30c8a5ef0264c\n",
      "\n",
      "NONE TYPE DETECTED\n",
      "Extracted 17 job descriptions.\n"
     ]
    }
   ],
   "source": [
    "descriptions = {}\n",
    "for i in range(641, len(jk)):\n",
    "\n",
    "    #last job scraped was i = 657. start at i = 658 next. go 300.\n",
    "    \n",
    "#     if i < len(jj)//4 or i > len(jj)*3//4:\n",
    "#         print(i)\n",
    "#         header = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36\"}\n",
    "#     else:\n",
    "#         header = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36\"}\n",
    "    \n",
    "    header = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\"}\n",
    "    jp= requests.get(f\"https://www.indeed.com/viewjob?jk={jk[i]}\", headers = header)\n",
    "\n",
    "    print(f\"Request for {i}/{len(jk)} jobs\")\n",
    "    print(f\"https://www.indeed.com/viewjob?jk={jk[i]}\\n\")\n",
    "    \n",
    "    jp_soup= bs(jp.text,'html.parser')\n",
    "#     print(jp_soup)\n",
    "    raw_desc = (jp_soup.find(\"div\",{\"class\":\"jobsearch-jobDescriptionText\"}))\n",
    "#     print(raw_desc)\n",
    "    \n",
    "    if raw_desc is None:\n",
    "        print(\"NONE TYPE DETECTED\")\n",
    "        break\n",
    "    \n",
    "    try:\n",
    "        descriptions[i] =(raw_desc.text.strip())\n",
    "    except AttributeError:\n",
    "        descriptions[i] = \"\"\n",
    "\n",
    "#create list from descriptions dictionary values... this is what we will append to the jj dataframe.\n",
    "descriptions_list = (list(descriptions.values()))\n",
    "\n",
    "print(f'Extracted {len(descriptions_list)} job descriptions.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c782f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_jobs = pd.DataFrame(descriptions_list, columns=[\"job_descriptions\"])\n",
    "desc_jobs.to_csv('jobdesc_641_to_657.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "763d97bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "jj_test = jj\n",
    "jj_test['job_num'] = jj_test['Unnamed: 0'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24894dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_descriptions</th>\n",
       "      <th>job_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FREE FLOW WINESJob DescriptionTitle:  Director...</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>About UsSatco is a family-owned and operated m...</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLANTA is building a team of inclusive, strate...</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Relocation Assistance Offered Within Country\\n...</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Job ID: 278719United Companies, is a CRH Compa...</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We are seeking individuals that are highly ski...</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Job Description:\\n\\nSummer Student Temp\\nColla...</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ERM is seeking a motivated Air Quality Staff C...</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Overview:\\n\\n**This position will be: Hybrid: ...</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Peraton Overview\\n\\nPeraton drives missions of...</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Integrated Supply Chain Entry Level Full Time ...</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Division of Finance and Administration (DF...</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Job Title:  Energy Analytics Intern (Summer 20...</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>About JLL –\\nWe’re JLL—a leading professional ...</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Curaleaf Holdings, Inc. (CSE: CURA) (OTCQX: CU...</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Agilent inspires and supports discoveries that...</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Yum is seeking a Technical Sourcer to develop ...</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     job_descriptions  job_num\n",
       "0   FREE FLOW WINESJob DescriptionTitle:  Director...      641\n",
       "1   About UsSatco is a family-owned and operated m...      642\n",
       "2   PLANTA is building a team of inclusive, strate...      643\n",
       "3   Relocation Assistance Offered Within Country\\n...      644\n",
       "4   Job ID: 278719United Companies, is a CRH Compa...      645\n",
       "5   We are seeking individuals that are highly ski...      646\n",
       "6   Job Description:\\n\\nSummer Student Temp\\nColla...      647\n",
       "7   ERM is seeking a motivated Air Quality Staff C...      648\n",
       "8   Overview:\\n\\n**This position will be: Hybrid: ...      649\n",
       "9   Peraton Overview\\n\\nPeraton drives missions of...      650\n",
       "10  Integrated Supply Chain Entry Level Full Time ...      651\n",
       "11  The Division of Finance and Administration (DF...      652\n",
       "12  Job Title:  Energy Analytics Intern (Summer 20...      653\n",
       "13  About JLL –\\nWe’re JLL—a leading professional ...      654\n",
       "14  Curaleaf Holdings, Inc. (CSE: CURA) (OTCQX: CU...      655\n",
       "15  Agilent inspires and supports discoveries that...      656\n",
       "16  Yum is seeking a Technical Sourcer to develop ...      657"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_jobs['job_num']=[x for x in range(641,658)]\n",
    "# desc_jobs.drop(['job_key'], inplace=True, axis = 1)\n",
    "desc_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e5cbcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_onkey = jj_test.merge(desc_jobs, on = \"job_num\", how = \"inner\")\n",
    "jobs_onkey\n",
    "jobs_onkey.to_csv('jobs_increment_scrape_641_657.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a82fd17",
   "metadata": {},
   "source": [
    "## Extracting Company Pages using Company Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "657b6337",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Gedeon GRC Consulting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>California State University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>World Wide Technology, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>EME Consulting Engineering Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Indian Nations Council of Governments (INCOG)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>Goby Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>LG Vehicle Components</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>101</td>\n",
       "      <td>GreenPrint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>102</td>\n",
       "      <td>Hines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>103</td>\n",
       "      <td>Planta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                   company_name\n",
       "0             0                          Gedeon GRC Consulting\n",
       "1             1                    California State University\n",
       "2             2                    World Wide Technology, Inc.\n",
       "3             3               EME Consulting Engineering Group\n",
       "4             4  Indian Nations Council of Governments (INCOG)\n",
       "..          ...                                            ...\n",
       "99           99                                       Goby Inc\n",
       "100         100                          LG Vehicle Components\n",
       "101         101                                     GreenPrint\n",
       "102         102                                          Hines\n",
       "103         103                                         Planta\n",
       "\n",
       "[104 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Open the file you want to extract company_names from here\n",
    "\n",
    "keys = pd.read_csv('missingcompanyinfo.csv')\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec427b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jamie Dimon\n",
      "1799\n",
      "more than 10,000\n",
      "more than $10B (USD)\n",
      "Financial Services\n"
     ]
    }
   ],
   "source": [
    "## tester\n",
    "\n",
    "html_doc = \"\"\"\n",
    "<li class=\"title\"><span>The Dormouse's story</span><span> by Alice </span</li>\n",
    "<ul class=\"css-ynb318-Box eu4oa1w0\"><li data-testid=\"companyInfo-ceo\" class=\"css-1m23au9-Box eu4oa1w0\"><div class=\"css-1et0vwh-Box eu4oa1w0\">CEO</div><div class=\"css-1cljifo-Box eu4oa1w0\">Jamie Dimon</div></li><li data-testid=\"companyInfo-founded\" class=\"css-1m23au9-Box eu4oa1w0\"><div class=\"css-1et0vwh-Box eu4oa1w0\">Founded</div><div class=\"css-1cljifo-Box eu4oa1w0\">1799</div></li><li data-testid=\"companyInfo-employee\" class=\"css-1m23au9-Box eu4oa1w0\"><div class=\"css-1et0vwh-Box eu4oa1w0\">Company size</div><div class=\"css-1cljifo-Box eu4oa1w0\"><div class=\"css-4zutel-Box eu4oa1w0\"><span><span>more than</span> 10,000</span></div></div></li><li data-testid=\"companyInfo-revenue\" class=\"css-1m23au9-Box eu4oa1w0\"><div class=\"css-1et0vwh-Box eu4oa1w0\">Revenue</div><div class=\"css-1cljifo-Box eu4oa1w0\"><div class=\"css-4zutel-Box eu4oa1w0\"><span><span>more than</span> $10B (USD)</span></div></div></li><li data-testid=\"companyInfo-industry\" class=\"css-1m23au9-Box eu4oa1w0\"><div class=\"css-1et0vwh-Box eu4oa1w0\">Industry</div><div class=\"css-1cljifo-Box eu4oa1w0\">Financial Services</div></li></ul>\n",
    "\"\"\"\n",
    "\n",
    "soup = bs(html_doc, 'html.parser')\n",
    "\n",
    "# print(soup.prettify())\n",
    "\n",
    "for ii in soup.find_all(name=\"li\"):\n",
    "    if ii.get('data-testid') == 'companyInfo-ceo':\n",
    "        print(re.sub('CEO', '', ii.text)) \n",
    "    elif ii.get('data-testid') == 'companyInfo-founded':\n",
    "        print(re.sub('Founded', '', ii.text)) \n",
    "    elif ii.get('data-testid') == 'companyInfo-employee':\n",
    "        print(re.sub('Company size', '', ii.text)) \n",
    "    elif ii.get('data-testid') == 'companyInfo-revenue':\n",
    "        print(re.sub('Revenue', '',ii.text)) \n",
    "    elif ii.get('data-testid') == 'companyInfo-industry':\n",
    "        print(re.sub('Industry', '', ii.text)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53ec2ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Gedeon-GRC-Consulting REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "1 California-State-University REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "2 World-Wide-Technology REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "3 EME-Consulting-Engineering-Group REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "4 Indian-Nations-Council-of-Governments-(INCOG) REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "5 Universal-Leaf-Tobacco-Co.-Inc. REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "6 Studio-School---Los-Angeles PAGE NOT FOUND\n",
      "7 Epsten-Group REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "8 Home-Innovation-Research-Labs REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "9 Onward-Energy REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "10 Shenandoah-Valley-Organic REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "11 ima-Design REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "12 City-of-Naples REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "13 Benson-Hill REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "14 Cooper-Carry REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "15 US-Surface-Transportation-Board REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "16 Land-O’Lakes PAGE NOT FOUND\n",
      "17 Virgin-Hyperloop REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "18 US-Architect-of-the-Capitol PAGE NOT FOUND\n",
      "19 Common-Ground-Food-Co-op PAGE NOT FOUND\n",
      "20 Eastern-Research-Group REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "21 The-Cadmus-Group REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "22 National-Sustainable-Agriculture-Coalition REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "23 University-of-MO-Columbia REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "24 Goby-Inc REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "25 Aspiration-Partners REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "26 Spirit-Environmental REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "27 Charlotte's-Web REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "28 City-of-Columbia REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "29 Partner-Energy REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "30 SI-Group REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "31 Hamer-Environmental REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "32 Eiger-Marketing REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "33 Rinker-Design-Associates REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "34 Eastern-Research-Group REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "35 Hamer-Environmental REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "36 Lake-Forest REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "37 University-of-Florida REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "38 Dedham REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "39 US-Bureau-of-Land-Management REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "40 Land-O’Lakes PAGE NOT FOUND\n",
      "41 Land-O’Lakes PAGE NOT FOUND\n",
      "42 Universal-Leaf-Tobacco-Co.-Inc. REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "43 Fisker-Inc REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "44 Zeroshop.co REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "45 Fisker-Inc REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "46 The-State-Education-Resource-Center-(SERC) REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "47 The-Earth-Partners REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "48 The-State-Education-Resource-Center-(SERC) REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "49 Cooper-Carry REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "50 State-of-Washington-Dept.-of-Commerce REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "51 Filoli-Historic-House-and-Garden REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "52 High-Meadow-Farm REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "53 Washington-River-Protection-Solutions-(WRPS) REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "54 GreenWorks-Environmental REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "55 River-Valley-Market-Llc REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "56 Goodfair REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "57 Cooper-Carry REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "58 State-of-Washington-Dept.-of-Commerce REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "59 Filoli-Historic-House-and-Garden REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "60 BRS REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "61 SLR-Consulting REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "62 Fisker-Inc REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "63 Benson-Hill REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "64 The-Cadmus-Group REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "65 US-Federal-Highway-Administration PAGE NOT FOUND\n",
      "66 DCR--Water-Supply-&-Protection PAGE NOT FOUND\n",
      "67 Benson-Hill REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "68 The-Cadmus-Group REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "69 Lufkin-Industries REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "70 Summersalt REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "71 EBP-US REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "72 Meridian-Consulting REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "73 Altura-Associates REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "74 The-Rector-&-Visitors-of-the-University-of-Virgini... PAGE NOT FOUND\n",
      "75 Hart-to-Hart-Farm-&-Education-Center PAGE NOT FOUND\n",
      "76 Meridian-Consulting REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "77 Land-O’Lakes PAGE NOT FOUND\n",
      "78 PERIMETER-SOLUTIONS REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "79 Diocese-of-Saginaw REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "80 ESC-Polytech-Consultants REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "81 Oneida-ESC-Group REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "82 Public-Health-Advocates REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "83 David-Energy REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "84 Rinker-Design-Associates REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "85 Council-of-the-Great-Lakes-Region PAGE NOT FOUND\n",
      "86 Rinker-Design-Associates REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "87 Council-of-the-Great-Lakes-Region PAGE NOT FOUND\n",
      "88 UnitedHealth-Group REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "89 Counterpart-International REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "90 Northeastern-University REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "91 Cleantech-Group REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "92 US-Surface-Transportation-Board REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "93 Essilor REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "94 River-Valley-Market-Llc REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "95 Goodfair REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "96 Land-O’Lakes PAGE NOT FOUND\n",
      "97 Umatilla-County REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "98 Sheladia-Associates REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "99 Goby-Inc REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "100 LG-Vehicle-Components REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "101 GreenPrint REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "102 Hines REQUEST SUCCESSFUL\n",
      "\tInfo Extract SUCCESS\n",
      "103 Planta REQUEST SUCCESSFUL\n",
      "\tNONE TYPE DETECTED\n",
      "Appended 53 companies to cc list\n",
      "Page Not Found for 14 companies\n",
      "No info for 51 companies\n"
     ]
    }
   ],
   "source": [
    "cc = []\n",
    "counter = 0\n",
    "pagenotfound = 0\n",
    "noinfo = 0\n",
    "\n",
    "for c in range(len(keys)):\n",
    "    # last scrape was c=352. start at c=353\n",
    "    cd = {'ceo': '-1',\n",
    "          'founded': '-1',\n",
    "          'size': '-1',\n",
    "          'revenue': '-1',\n",
    "          'industry': '-1'       \n",
    "         }\n",
    "    \n",
    "    cname = keys['company_name'][c]\n",
    "    \n",
    "    #formatting cname for URL\n",
    "    #Extract name before comma\n",
    "    fcname = re.split(r',+',cname)\n",
    "    \n",
    "    #replace space with -\n",
    "    fcname = re.sub(r'\\s','-',fcname[0])\n",
    "    \n",
    "    cr = requests.get(f'https://www.indeed.com/cmp/{fcname}')\n",
    "    #404 is page not found\n",
    "    #200 is good\n",
    "    if c % 2 == 0 and c % 5 == 0 and c < 10:\n",
    "        time.sleep(7)\n",
    "    elif c % 2 != 0 and c % 5 == 0 and c < 10:\n",
    "        time.sleep(4)\n",
    "    elif c% 3 != 0 and c < 10:\n",
    "        time.sleep(3)\n",
    "    elif c % 2 == 0 and c % 5 == 0 and c >= 10:\n",
    "        time.sleep(2)\n",
    "    elif c % 2 != 0 and c % 5 == 0 and c >= 10:\n",
    "        time.sleep(9)\n",
    "    elif c % 3 != 0 and c >= 10:\n",
    "        time.sleep(5)\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    if cr.status_code == 200:\n",
    "        sp = bs(cr.text, 'lxml')\n",
    "        soup = sp.find('ul', {\"class\": 'eu4oa1w0'})\n",
    "        \n",
    "        print(f'{c} {fcname} REQUEST SUCCESSFUL')\n",
    "        \n",
    "        \n",
    "        if soup is None:\n",
    "            print(\"\\tNONE TYPE DETECTED\")\n",
    "            noinfo += 1\n",
    "            cc.append(cd)\n",
    "            continue\n",
    "        \n",
    "        for ii in soup.find_all(name=\"li\"):\n",
    "            if ii.get('data-testid') == 'companyInfo-ceo':\n",
    "                cd['ceo'] = (re.sub('CEO', '', ii.text)) \n",
    "            elif ii.get('data-testid') == 'companyInfo-founded':\n",
    "                cd['founded'] = (re.sub('Founded', '', ii.text)) \n",
    "            elif ii.get('data-testid') == 'companyInfo-employee':\n",
    "                cd['size'] = (re.sub('Company size', '', ii.text)) \n",
    "            elif ii.get('data-testid') == 'companyInfo-revenue':\n",
    "                cd['revenue'] = (re.sub('Revenue', '',ii.text)) \n",
    "            elif ii.get('data-testid') == 'companyInfo-industry':\n",
    "                cd['industry'] = (re.sub('Industry', '', ii.text)) \n",
    "        print(\"\\tInfo Extract SUCCESS\")\n",
    "            \n",
    "    else:\n",
    "        print(f'{c} {fcname} PAGE NOT FOUND')\n",
    "        pagenotfound +=1\n",
    "    \n",
    "    \n",
    "    counter += 1\n",
    "    cc.append(cd)\n",
    "    \n",
    "print(f'Appended {counter} companies to cc list')\n",
    "print(f'Page Not Found for {pagenotfound} companies') # 8 comp (353`641),, \n",
    "print(f'No info for {noinfo} companies')  #23 (353`641),, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ac9b3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd=pd.DataFrame(cc)\n",
    "cd = cd.join(keys)\n",
    "cd.to_csv('missingcompanyinfo_filled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "688da5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ul class=\"css-ynb318-Box eu4oa1w0\"><style data-emotion=\"css 1m23au9-Box\">.css-1m23au9-Box{box-sizing:border-box;margin:0;min-width:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;background-color:#ffffff;border:1px solid #f3f2f1;border-radius:0.5rem;padding:16px;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:relative;-webkit-flex:0 0 120px;-ms-flex:0 0 120px;flex:0 0 120px;margin:8px;box-sizing:border-box;word-wrap:break-word;}@supports (display: grid){.css-1m23au9-Box{margin:0;-webkit-flex:0 0 147px;-ms-flex:0 0 147px;flex:0 0 147px;}}</style><li class=\"css-1m23au9-Box eu4oa1w0\" data-testid=\"companyInfo-ceo\"><style data-emotion=\"css 1et0vwh-Box\">.css-1et0vwh-Box{box-sizing:border-box;margin:0;min-width:0;margin-bottom:16px;font-size:14px;font-weight:700;display:block;}</style><div class=\"css-1et0vwh-Box eu4oa1w0\">CEO</div><style data-emotion=\"css 1cljifo-Box\">.css-1cljifo-Box{box-sizing:border-box;margin:0;min-width:0;font-size:16px;}</style><div class=\"css-1cljifo-Box eu4oa1w0\">Michael S. Burke</div></li><li class=\"css-1m23au9-Box eu4oa1w0\" data-testid=\"companyInfo-founded\"><div class=\"css-1et0vwh-Box eu4oa1w0\">Founded</div><div class=\"css-1cljifo-Box eu4oa1w0\">2011</div></li><li class=\"css-1m23au9-Box eu4oa1w0\" data-testid=\"companyInfo-employee\"><div class=\"css-1et0vwh-Box eu4oa1w0\">Company size</div><div class=\"css-1cljifo-Box eu4oa1w0\"><style data-emotion=\"css 4zutel-Box\">.css-4zutel-Box{box-sizing:border-box;margin:0;min-width:0;}.css-4zutel-Box span{font-size:16px;color:#2D2D2D;}.css-4zutel-Box span span{font-size:12px;color:#6F6F6F;display:block;}</style><div class=\"css-4zutel-Box eu4oa1w0\"><span><span>more than</span> 10,000</span></div></div></li><li class=\"css-1m23au9-Box eu4oa1w0\" data-testid=\"companyInfo-revenue\"><div class=\"css-1et0vwh-Box eu4oa1w0\">Revenue</div><div class=\"css-1cljifo-Box eu4oa1w0\"><div class=\"css-4zutel-Box eu4oa1w0\"><span><span>more than</span> $10B (USD)</span></div></div></li><li class=\"css-1m23au9-Box eu4oa1w0\" data-testid=\"companyInfo-industry\"><div class=\"css-1et0vwh-Box eu4oa1w0\">Industry</div><div class=\"css-1cljifo-Box eu4oa1w0\">Construction &amp; Facilities Services</div></li></ul>\n"
     ]
    }
   ],
   "source": [
    "#test to see if we reached captcha yet.\n",
    "fname=\"AECOM\"\n",
    "cr = requests.get(f'https://www.indeed.com/cmp/{fname}')\n",
    "\n",
    "time.sleep(3)\n",
    "    \n",
    "sp = bs(cr.text, 'lxml')\n",
    "soup = sp.find('ul', {\"class\": 'eu4oa1w0'})\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e45c319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>641</td>\n",
       "      <td>Free Flow Wines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>642</td>\n",
       "      <td>Satco, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>643</td>\n",
       "      <td>Planta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>644</td>\n",
       "      <td>Tom's of Maine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>645</td>\n",
       "      <td>CRH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>646</td>\n",
       "      <td>Brodie Builders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>647</td>\n",
       "      <td>3M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>648</td>\n",
       "      <td>ERM Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>649</td>\n",
       "      <td>City of Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>650</td>\n",
       "      <td>Peraton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>651</td>\n",
       "      <td>Cummins Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>652</td>\n",
       "      <td>University of California - Irvine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>653</td>\n",
       "      <td>Steven Winter Associates, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>654</td>\n",
       "      <td>JLL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>655</td>\n",
       "      <td>Curaleaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>656</td>\n",
       "      <td>Agilent Technologies, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>657</td>\n",
       "      <td>Yum! Brands</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0.1                       company_name\n",
       "0            641                    Free Flow Wines\n",
       "1            642                        Satco, Inc.\n",
       "2            643                             Planta\n",
       "3            644                     Tom's of Maine\n",
       "4            645                                CRH\n",
       "5            646                    Brodie Builders\n",
       "6            647                                 3M\n",
       "7            648                          ERM Group\n",
       "8            649                     City of Boston\n",
       "9            650                            Peraton\n",
       "10           651                       Cummins Inc.\n",
       "11           652  University of California - Irvine\n",
       "12           653     Steven Winter Associates, Inc.\n",
       "13           654                                JLL\n",
       "14           655                           Curaleaf\n",
       "15           656         Agilent Technologies, Inc.\n",
       "16           657                        Yum! Brands"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnames = pd.DataFrame(keys[['Unnamed: 0.1','company_name']])\n",
    "# cnames['keyn'] = [x for x in range(641)]\n",
    "# list(cnames['company_name'][0:190])\n",
    "cnames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5668e492",
   "metadata": {},
   "source": [
    "#### Helpful resource for pandas merging...\n",
    "https://stackoverflow.com/questions/53645882/pandas-merging-101/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a99b862b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>company_name</th>\n",
       "      <th>ceo</th>\n",
       "      <th>founded</th>\n",
       "      <th>size</th>\n",
       "      <th>revenue</th>\n",
       "      <th>industry</th>\n",
       "      <th>keyn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>641</td>\n",
       "      <td>Free Flow Wines</td>\n",
       "      <td>-1</td>\n",
       "      <td>2009</td>\n",
       "      <td>less than 10</td>\n",
       "      <td>$5M to $25M (USD)</td>\n",
       "      <td>Food &amp; Beverage Manufacturing</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>642</td>\n",
       "      <td>Satco, Inc.</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Banking &amp; Lending</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>643</td>\n",
       "      <td>Planta</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>644</td>\n",
       "      <td>Tom's of Maine</td>\n",
       "      <td>-1</td>\n",
       "      <td>2006</td>\n",
       "      <td>51 to 200</td>\n",
       "      <td>$25M to $100M (USD)</td>\n",
       "      <td>-1</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>645</td>\n",
       "      <td>CRH</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Construction, Repair &amp; Facilities Services</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>646</td>\n",
       "      <td>Brodie Builders</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Architectural &amp; Engineering Services</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>647</td>\n",
       "      <td>3M</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>648</td>\n",
       "      <td>ERM Group</td>\n",
       "      <td>-1</td>\n",
       "      <td>1971</td>\n",
       "      <td>1001 to 5,000</td>\n",
       "      <td>$100M to $500M (USD)</td>\n",
       "      <td>Management &amp; Consulting</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>649</td>\n",
       "      <td>City of Boston</td>\n",
       "      <td>Marty Walsh</td>\n",
       "      <td>1630</td>\n",
       "      <td>more than 10,000</td>\n",
       "      <td>-1</td>\n",
       "      <td>Government &amp; Public Administration</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>650</td>\n",
       "      <td>Peraton</td>\n",
       "      <td>Stu Shea</td>\n",
       "      <td>2017</td>\n",
       "      <td>more than 10,000</td>\n",
       "      <td>$5B to $10B (USD)</td>\n",
       "      <td>Aerospace &amp; Defense</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>651</td>\n",
       "      <td>Cummins Inc.</td>\n",
       "      <td>Tom Linebarger</td>\n",
       "      <td>1919</td>\n",
       "      <td>more than 10,000</td>\n",
       "      <td>more than $10B (USD)</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>652</td>\n",
       "      <td>University of California - Irvine</td>\n",
       "      <td>-1</td>\n",
       "      <td>1965</td>\n",
       "      <td>more than 10,000</td>\n",
       "      <td>$1B to $5B (USD)</td>\n",
       "      <td>Education</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>653</td>\n",
       "      <td>Steven Winter Associates, Inc.</td>\n",
       "      <td>-1</td>\n",
       "      <td>1972</td>\n",
       "      <td>51 to 200</td>\n",
       "      <td>$5M to $25M (USD)</td>\n",
       "      <td>-1</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>654</td>\n",
       "      <td>JLL</td>\n",
       "      <td>Christian Ulbrich</td>\n",
       "      <td>1985</td>\n",
       "      <td>more than 10,000</td>\n",
       "      <td>more than $10B (USD)</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>655</td>\n",
       "      <td>Curaleaf</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Retail &amp; Wholesale</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>656</td>\n",
       "      <td>Agilent Technologies, Inc.</td>\n",
       "      <td>Mike McMullen</td>\n",
       "      <td>1999</td>\n",
       "      <td>more than 10,000</td>\n",
       "      <td>$1B to $5B (USD)</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>657</td>\n",
       "      <td>Yum! Brands</td>\n",
       "      <td>David Gibbs</td>\n",
       "      <td>1997</td>\n",
       "      <td>1001 to 5,000</td>\n",
       "      <td>$1B to $5B (USD)</td>\n",
       "      <td>Restaurants &amp; Food Service</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0.1                       company_name                ceo  \\\n",
       "0            641                    Free Flow Wines                 -1   \n",
       "1            642                        Satco, Inc.                 -1   \n",
       "2            643                             Planta                 -1   \n",
       "3            644                     Tom's of Maine                 -1   \n",
       "4            645                                CRH                 -1   \n",
       "5            646                    Brodie Builders                 -1   \n",
       "6            647                                 3M                 -1   \n",
       "7            648                          ERM Group                 -1   \n",
       "8            649                     City of Boston        Marty Walsh   \n",
       "9            650                            Peraton           Stu Shea   \n",
       "10           651                       Cummins Inc.     Tom Linebarger   \n",
       "11           652  University of California - Irvine                 -1   \n",
       "12           653     Steven Winter Associates, Inc.                 -1   \n",
       "13           654                                JLL  Christian Ulbrich   \n",
       "14           655                           Curaleaf                 -1   \n",
       "15           656         Agilent Technologies, Inc.      Mike McMullen   \n",
       "16           657                        Yum! Brands        David Gibbs   \n",
       "\n",
       "   founded              size               revenue  \\\n",
       "0     2009      less than 10     $5M to $25M (USD)   \n",
       "1       -1                -1                    -1   \n",
       "2       -1                -1                    -1   \n",
       "3     2006         51 to 200   $25M to $100M (USD)   \n",
       "4       -1                -1                    -1   \n",
       "5       -1                -1                    -1   \n",
       "6       -1                -1                    -1   \n",
       "7     1971     1001 to 5,000  $100M to $500M (USD)   \n",
       "8     1630  more than 10,000                    -1   \n",
       "9     2017  more than 10,000     $5B to $10B (USD)   \n",
       "10    1919  more than 10,000  more than $10B (USD)   \n",
       "11    1965  more than 10,000      $1B to $5B (USD)   \n",
       "12    1972         51 to 200     $5M to $25M (USD)   \n",
       "13    1985  more than 10,000  more than $10B (USD)   \n",
       "14      -1                -1                    -1   \n",
       "15    1999  more than 10,000      $1B to $5B (USD)   \n",
       "16    1997     1001 to 5,000      $1B to $5B (USD)   \n",
       "\n",
       "                                      industry  keyn  \n",
       "0                Food & Beverage Manufacturing   641  \n",
       "1                            Banking & Lending   642  \n",
       "2                                           -1   643  \n",
       "3                                           -1   644  \n",
       "4   Construction, Repair & Facilities Services   645  \n",
       "5         Architectural & Engineering Services   646  \n",
       "6                                           -1   647  \n",
       "7                      Management & Consulting   648  \n",
       "8           Government & Public Administration   649  \n",
       "9                          Aerospace & Defense   650  \n",
       "10                               Manufacturing   651  \n",
       "11                                   Education   652  \n",
       "12                                          -1   653  \n",
       "13                                 Real Estate   654  \n",
       "14                          Retail & Wholesale   655  \n",
       "15                                  Healthcare   656  \n",
       "16                  Restaurants & Food Service   657  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_info = pd.DataFrame(cc)\n",
    "comp_info['keyn'] = [x for x in range(641,658)]\n",
    "comp_info\n",
    "cc_info = cnames.merge(comp_info, how = \"inner\", left_on ='Unnamed: 0.1', right_on = 'keyn')\n",
    "cc_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f8f5f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_info.to_csv('companyinfo_641_657.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14766e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "combjobs = pd.read_csv('combined_jobs_0_640.csv')\n",
    "compinfo = pd.read_csv('companyinfo_0_33.csv')\n",
    "all_info_0_33 = combjobs.merge(compinfo, how = \"left\", on='company_name')\n",
    "all_info_0_33.drop('Unnamed: 0_y', inplace= True, axis=1)\n",
    "all_info_0_33.drop('Unnamed: 0_x', inplace= True, axis=1)\n",
    "all_info_0_33.to_csv('allinfo_0_33.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc7dfbf",
   "metadata": {},
   "source": [
    "### First increment transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a516afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out dated. this was for first increment transform\n",
    "\n",
    "# jj is already a dataframe, after reading the job keys csv\n",
    "# basic_jobs = pd.DataFrame(jj)\n",
    "# desc_jobs = pd.DataFrame(descriptions_list, columns=[\"job_descriptions\"])\n",
    "jobs_ = pd.concat([jj, desc_jobs], axis=1)\n",
    "jobs_['job_descriptions']\n",
    "jobs_.to_csv('jobs_increment_scrape_336.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:finalproject_env] *",
   "language": "python",
   "name": "conda-env-finalproject_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
